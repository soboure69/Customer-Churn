{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff7b84b",
   "metadata": {},
   "source": [
    "# Mod√©lisation \n",
    "\n",
    "Cette phase de mod√©lisation pour le projet de pr√©diction du d√©sabonnement client (Customer Churn) est l'√©tape o√π des algorithmes de Machine Learning sont utilis√©s pour construire un mod√®le capable de pr√©dire quels clients sont susceptibles de se d√©sabonner des services d'une entreprise, sp√©cifiquement une entreprise de t√©l√©communication dans ce projet.\n",
    "\n",
    "L'objectif est de cr√©er un mod√®le de classification qui peut automatiquement pr√©dire si un client va se d√©sabonner ou non. Cette pr√©diction est fondamentale pour les entreprises, car **le co√ªt de r√©tention d'un client existant est bien inf√©rieur √† celui de l'acquisition d'un nouveau client**. En identifiant les clients √† risque, l'entreprise peut lancer des campagnes marketing cibl√©es pour les fid√©liser.\n",
    "## 1. Choix de la M√©trique d'√âvaluation\n",
    "**Quelle m√©trique choisir pour √©valuer la performance des mod√®les?**\n",
    "\n",
    "Faudrait comprendre au pr√©alable ce qu'on appelle matrice de confusion.\n",
    "\n",
    "![image_matrice_confusion.png](attachment:image_matrice_confusion.png)\n",
    "\n",
    "\n",
    "la matrice de confusion est un outil indispensable pour √©valuer la performance des mod√®les de classification. C'est une matrice carr√©e qui rapporte le nombre de vrais positifs (*True Positives* ou TP), vrais n√©gatifs (*True N√©gatives* ou TN), faux positifs (*False Positive* ou FP) et faux n√©gatifs (*False Negatives* ou FN).\n",
    "\n",
    "Dans notre cas, **le positif c'est 1 : le client s'est d√©sabonn√©** et **le n√©gatif c'est 0 : le client ne s'est pas d√©sabonn√©** .\n",
    "\n",
    "- **TP** : Le client s'est d√©sabonn√© et le mod√®le pr√©dit qu'il s'est d√©sabonn√©;\n",
    "- **TN** : Le client ne s'est pas d√©sabonn√© et le mod√®le pr√©dit qu'il ne s'est pas d√©sabonn√©.\n",
    "\n",
    "Les deux cas ci-dessus (TP et TN) sont les bons cas. Mais FP et FN sont les mauvais cas :\n",
    "- **FP** : Le client ne s'est pas d√©sabonn√© et le mod√®le pr√©dit qu'il s'est d√©sabonn√©;\n",
    "- **FN** : Le client s'est d√©sabonn√© et le mod√®le pr√©dit qu'il ne s'est pas d√©sabonn√©.\n",
    "\n",
    "\n",
    "‚Ä¢ Interpr√©tation Visuelle :\n",
    "\n",
    "    ‚ó¶ La diagonale (TP et TN) repr√©sente les pr√©dictions correctes : plus les chiffres sur cette diagonale sont √©lev√©s, meilleur est le mod√®le.\n",
    "\n",
    "    ‚ó¶ Les valeurs hors diagonale (FP et FN) repr√©sentent les erreurs de pr√©diction : plus ces chiffres sont √©lev√©s, pire est le mod√®le.\n",
    "\n",
    "![image_matrice_confusion2.png](attachment:image_matrice_confusion2.png)\n",
    "Les choix de m√©triques : [üëâ](https://scikit-learn.org/stable/api/sklearn.metrics.html)\n",
    "\n",
    "**M√©triques de classification** : ``accuracy_score``, ``f1_score``, ``precision_score``, ``recall_score``, etc.\n",
    "\n",
    "\n",
    "- **accuracy**: L'exactitude, c'est la pr√©cision globale du mod√®le (***Accuracy*** en anglais) est la proportion de pr√©visions correctes, c'est-√†-dire la somme du nombre de vrais n√©gatifs et vrais positifs divis√© par le nombre total des obserations. Elle se calcule donc par la formule ci-dessous:\n",
    "\n",
    "$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "Il faudrait faire attention √† la pr√©cision globale. Une forte pr√©cision globale ne signifie pas forc√©ment que le mod√®le est performant. Le choix de la m√©trique pour quantifier la performance du mod√®le doit se faire en fonction du contexte de l'√©tude, c'est-√†-dire de la probl√©matique qu'on veut r√©soudre.\n",
    "\n",
    "Lorsqu'il y a un probl√®me de d√©s√©quilibre de classe, la pr√©cision globale n'est pas une bonne m√©trique d'√©valuation de la performance du mod√®le.\n",
    "\n",
    "*precision* et *recall* sont des m√©triques tr√®s utilis√©es surtout lorsque les classes de la variable cible sont tr√®s d√©s√©quilibr√©es.\n",
    "\n",
    "- **precision**: La pr√©cision est l'indicateur qui nous indique, sur tous les points positifs pr√©dits, combien √©taient de vrais positifs.\n",
    "Proportion de pr√©dictions positives correctes :\n",
    "\n",
    "$Precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "- **recall**: cette m√©trique montre la capacit√© du mod√®le √† identifier tous le vrais positifs.\n",
    "Recall (Rappel ou Sensibilit√©) -> Proportion de vrais positifs d√©tect√©s :\n",
    "\n",
    "$Recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "L'am√©lioration de *precision* diminue *recall* et vice-versa. Alors que faire?\n",
    "\n",
    "Fort heureusement, il y a une m√©trique qui contient √† la fois la sensibilit√© et la sp√©cificit√©. C'est le F1 score.\n",
    "\n",
    "- **F1 score** : Moyenne harmonique de ***precision*** et de ***recall***. Elle se calcule donc par la formule:\n",
    "\n",
    "$F1 Score = 2 * \\frac{{Precision} * {Recall}}{{Precision} + {Recall}} = \\frac{2TP}{2TP + FP + FN}$\n",
    "\n",
    "Il est indispensable et incontournable de d√©terminer la m√©trique d'√©valuation avant de commencer √† entra√Æner les algorithmes.\n",
    "\n",
    "Le choix de la m√©trique d√©pend du contexte sp√©cifique de la probl√©matique √† r√©soudre (ex: d√©tection de cancer, fraude bancaire). \n",
    "\n",
    "Pour ce probl√®me de d√©sabonnement client, le F1-score est consid√©r√© comme le plus pertinent.\n",
    "\n",
    "Pour un mod√®le parfait, f1 score est √©gal √† 1 et la plus mauvaise performance est un mod√®le avec un f1 score √©gal √† 0.\n",
    "\n",
    "\n",
    "\n",
    "**On choisit donc le F1 score pour √©valuer la performance de chaque mod√®le qui sera construit.**\n",
    "## 2. S√©lection des Variables Pr√©dictives (Feature Selection)\n",
    "\n",
    "La Feature Selection est une √©tape cruciale avant l'entra√Ænement des algorithmes, visant √† optimiser le mod√®le.\n",
    "\n",
    "L'objectif est de d√©terminer les meilleures variables pr√©dictrices pour le mod√®le.\n",
    "\n",
    "Toutes les variables ne sont pas importantes pour expliquer la variable cible (le d√©sabonnement du client).\n",
    "\n",
    "La s√©lection des variables permet de r√©duire le bruit dans les donn√©es et d'√©viter le sur-ajustement (overfitting) du mod√®le.\n",
    "\n",
    "De plus, cela am√©liore l'interpr√©tabilit√© du mod√®le en r√©duisant la complexit√© due √† un grand nombre de variables.\n",
    "**M√©thode 1 : Importance des Caract√©ristiques (Feature Importance) via For√™t Al√©atoire (Random Forest)**\n",
    "\n",
    "- Principe : \n",
    "Les mod√®les bas√©s sur les arbres de d√©cision, comme la For√™t Al√©atoire, poss√®dent un attribut qui attribue une note d'importance √† chaque variable pr√©dictive.\n",
    "- Impl√©mentation :\n",
    "  - Un mod√®le simple de For√™t Al√©atoire (``RandomForestClassifier``) est entra√Æn√© sur les donn√©es d'entra√Ænement (``train_features`` et ``train_labels``) sans chercher les meilleurs hyperparam√®tres pour l'instant.\n",
    "  - Les scores d'importance des caract√©ristiques (``feature_importances_``) sont extraits et un tableau est cr√©√© pour visualiser l'importance de chaque variable.\n",
    "  - Les variables sont class√©es par ordre d√©croissant d'importance.\n",
    "# Selection des meilleures variables pr√©dictives\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_features, train_labels)\n",
    "print(classification_report(y_val, rf.predict(X_val)))\n",
    "# Importance des variables ind√©pendantes\n",
    "vars_imp = pd.DataFrame({'Variable': train_features.columns, 'Importance': rf.feature_importances_})\n",
    "vars_imp = vars_imp.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(data=vars_imp, x='Variable', y='Importance')\n",
    "plt.xticks(rotation=70)\n",
    "plt.title('Importance des variables pr√©dictrices')\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Score Importance de la variable')\n",
    "plt.show()\n",
    "On observe que : \n",
    "\n",
    "- Les variables **TotalCharges** (montant total factur√©), **tenure** (anciennet√© du client en mois) et **MonthlyCharges** (facture mensuelle) sont identifi√©es comme les plus importantes.\n",
    "\n",
    "- Les variables **SeniorCitizen** et **gender** (sexe du client) ont une importance tr√®s faible, voire nulle, on sugg√®re qu'elles n'ont pas un r√¥le significatif dans la pr√©diction du d√©sabonnement, ie aucune relation avec la variable cible.\n",
    "# Affichage des vars_imp\n",
    "vars_imp.reset_index(drop=True, inplace=True)\n",
    "vars_imp\n",
    "La s√©lection des meilleurs variables pr√©dictives est bas√©e sur un Seuil :\n",
    "- Pour √©liminer les variables moins pertinentes qui n'ajouteraient que du bruit, un seuil est choisi.\n",
    "- Seules les variables dont l'importance est sup√©rieure √† ce seuil sont conserv√©es pour la mod√©lisation.\n",
    "- Ce processus conduit √† la s√©lection d'un ensemble r√©duit de variables. Ce choix de seuil est flexible et peut √™tre ajust√© pour voir l'impact sur les r√©sultats\n",
    "# Variables s√©lectionn√©es pour les algorithmes\n",
    "seuil = 0.004  # Seuil pour la s√©lection des variables\n",
    "vars_selected = vars_imp[vars_imp['Importance'] > seuil]['Variable'].tolist()\n",
    "print(\"Variables s√©lectionn√©es pour les algorithmes :\", vars_selected)\n",
    "len(vars_selected)\n",
    "On a donc 28 variables finales, apr√®s √©limination de certaines.\n",
    "# Mise √† jour des donn√©es d'entra√Ænement, de validation et de test pour contenir ces variables s√©lectionn√©es\n",
    "train_features = train_features[vars_selected]\n",
    "X_val = X_val[vars_selected]\n",
    "X_test = X_test[vars_selected]\n",
    "X_test = X_test[vars_selected]\n",
    "**M√©thode2 : √âlimination R√©cursive de Caract√©ristiques (Recursive Feature Elimination - RFE)**\n",
    "\n",
    "L'algorithme Recursive Feature Elimination (RFE) est aussi une m√©thode de selection de variables pr√©dictives (Feature Selection). Elle vise √† trouver le sous-ensemble de variables qui maintient ou am√©liore la performance d'un mod√®le tout en r√©duisant sa complexit√©.\n",
    "\n",
    "On l'appliquera dans la suite √† chaque mod√®le entrain√©.\n",
    "## 3. Entra√Ænement, √âvaluation  des mod√®les et Ajustement des Hyperparam√®tre\n",
    "L'objectif principal de la mod√©lisation est de construire un mod√®le de classification capable de pr√©dire automatiquement si un client va se d√©sabonner ou non.\n",
    "\n",
    "Ce mod√®le permettra √† l'entreprise de t√©l√©communications de cibler les clients √† risque avec des campagnes marketing sp√©cifiques afin de les fid√©liser, √©tant donn√© que le co√ªt de r√©tention d'un client est bien inf√©rieur au co√ªt d'acquisition d'un nouveau client.\n",
    "Plusieurs algorithmes de Machine Learning et un r√©seau de neurones artificiel (Deep Learning simple) seront entra√Æn√©s afin de comparer leurs performances et de choisir le meilleur mod√®le.\n",
    "\n",
    "Les algorithmes test√©s incluent :\n",
    "\n",
    "- [R√©gression Logistique](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  \n",
    "- [For√™t Al√©atoire (Random Forest)](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)  \n",
    "- [Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)  \n",
    "- [Classificateur Perceptron Multicouche (MLP Classifier)](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) ‚Äî un r√©seau de neurones artificiel simple  \n",
    "- [Support Vector Machine (SVM)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "### 3.1 Entra√Ænement et √âvaluation de la R√©gression Logistique\n",
    "# Dictionnaire des hyperparam√®tres \n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 50, 100, 500],}\n",
    "\n",
    "# Objet GridSearchCV\n",
    "grid_logistic_class = GridSearchCV(estimator=LogisticRegression(random_state=seed, max_iter=500), \n",
    "                             param_grid=param_grid, \n",
    "                             scoring='f1', \n",
    "                             cv=5)\n",
    "\n",
    "# Entrainement de l'algorithme\n",
    "logistic_model = grid_logistic_class.fit(train_features, train_labels)\n",
    "\n",
    "# Meilleur score et meilleur hyperparam√®tre\n",
    "print(\"Meilleur score (f1) :\", grid_logistic_class.best_score_)\n",
    "print(\"Meilleur hyperparam√®tre (C) :\", grid_logistic_class.best_params_)\n",
    "print(\"Meilleur mod√®le :\", logistic_model.best_estimator_)\n",
    "Le mod√®le a un bon score d'entra√Ænement. Evaluons sa performance sur les donn√©es de validation afin d'appr√©cier sa capacit√© √† g√©n√©raliser sur de nouvelles donn√©es.\n",
    "# Fonction d'√©valuation de la performance d'un mod√®le\n",
    "\n",
    "def evaluate_model(model, features, labels):\n",
    "    pred = model.predict(features)\n",
    "    print(classification_report(labels, pred))\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(pd.crosstab(labels, pred, rownames=['R√©el'], colnames=['Pr√©dit']), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Matrice de confusion')\n",
    "    plt.show()\n",
    "# Evaluation du mod√®le de r√©gression logistique\n",
    "evaluate_model(logistic_model.best_estimator_, X_val, y_val)\n",
    "Pour la r√©gression logistique, l'F1-score de la classe positive est de 0.62 et la pr√©cision globale (accuracy) est de 0.75.\n",
    "Appliquons l'algorithme [Recursive Feature Elimination](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) (**RFE**) √† la r√©gression logistique pour r√©duire le nombre de variables pr√©dictrices. En effet, plus le mod√®le est complexe, plus il est difficile de l'interpr√©ter. \n",
    "# Cr√©ation d'une fonction de construction d'un mod√®le avec utilisation de l'algorithme RFE\n",
    "def build_model_with_rfe(model):\n",
    "    rfe_model = RFE(estimator=model, verbose=0)\n",
    "    rfe_model.fit(train_features, train_labels)\n",
    "    mask = rfe_model.support_\n",
    "    reduced_X = train_features.loc[:, mask]\n",
    "    print(f\"Les Variables s√©lectionn√©es par RFE : {reduced_X.columns.tolist()}\")\n",
    "    return rfe_model\n",
    "# Logistic Regression avec RFE\n",
    "rfe_logistic_model = build_model_with_rfe(logistic_model.best_estimator_)\n",
    "rfe_logistic_model\n",
    "# Nombre de variables s√©lectionn√©es apr√®s avoir appliqu√© la RFE\n",
    "print(\"Nombre de variables s√©lectionn√©es apr√®s RFE :\", rfe_logistic_model.n_features_)\n",
    "# Evaluation du mod√®le de r√©gression logistique avec RFE\n",
    "evaluate_model(rfe_logistic_model, X_val, y_val)\n",
    "L'algorithme Recursive Feature Elimination (RFE) appliqu√© √† la r√©gression logistique, a r√©duit le nombre de variables pr√©dictrices de 28 √† 14. Bien que les valeurs du F1-score de la classe positive et la pr√©cision globale soient inchang√©s, le mod√®le avec 14 variables est **pr√©f√©rable pour son interpr√©tabilit√© accrue** en raison de performances similaires.\n",
    "### 3.2 Entra√Ænement et √âvaluation de la For√™t Al√©atoire (Random Forest)\n",
    "# Dictionnaire des hyperparam√®tres pour Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100, 500, 1000],\n",
    "    'max_depth': [3, 5, 10, 20, None]\n",
    "}\n",
    "\n",
    "# Objet GridSearchCV\n",
    "grid_rf_class = GridSearchCV(estimator=RandomForestClassifier(random_state=seed), \n",
    "                             param_grid=param_grid_rf, \n",
    "                             scoring='f1', \n",
    "                             cv=5)\n",
    "\n",
    "# Entrainement du mod√®le de Random Forest\n",
    "rf_model = grid_rf_class.fit(train_features, train_labels)\n",
    "\n",
    "# Meilleur score et meilleur hyperparam√®tre\n",
    "print(\"Meilleur score (f1) :\", round(rf_model.best_score_, 3))\n",
    "print(\"Meilleur hyperparam√®tre (n_estimators, max_depth) :\", rf_model.best_params_)\n",
    "# Meilleur mod√®le\n",
    "print(\"Meilleur mod√®le :\", rf_model.best_estimator_)\n",
    "\n",
    "# Evaluation du mod√®le de f√¥r√™t al√©atoire\n",
    "evaluate_model(rf_model.best_estimator_, X_val, y_val)\n",
    "Compar√© aux valeurs du mod√®le de r√©gression logistique, le mod√®le de for√™t al√©atoire semble moins √©fficace.\n",
    "\n",
    "Appliquons la RFE\n",
    "# Random Forest avec RFE\n",
    "rfe_rf_model = build_model_with_rfe(rf_model.best_estimator_)\n",
    "rfe_rf_model\n",
    "# Evaluation du mod√®le de forest al√©atoire\n",
    "evaluate_model(rfe_rf_model, X_val, y_val)\n",
    "Au vue de ces valeurs, nous retiendrons le mod√®le de for√™t al√©atoire obtenu sans RFE.\n",
    "\n",
    "Passons √† la construction d'un mod√®le de r√©seau de neuronnes artificiel.\n",
    "### 3.3 Entra√Ænement et √âvaluation du Classificateur Perceptron Multicouche (MLP Classifier)\n",
    "# MLPClassifier\n",
    "mlp = MLPClassifier(random_state=seed, max_iter=1000)\n",
    "# Dictionnaire des hyperparam√®tres pour MLPClassifier\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,), (100,), (200,)],\n",
    "                    #'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                    #'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                    'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "# Objet GridSearchCV\n",
    "grid_mlp_class = GridSearchCV(estimator=mlp, param_grid=param_grid_mlp, \n",
    "                             scoring='f1', cv=5, n_jobs=-1)\n",
    "\n",
    "# Entrainement du mod√®le de MLPClassifier\n",
    "mlp_model = grid_mlp_class.fit(train_features, train_labels)\n",
    "# Meilleur score et meilleur hyperparam√®tre\n",
    "print(\"Meilleur score (f1) :\", round(mlp_model.best_score_, 3))\n",
    "print(\"Meilleur hyperparam√®tre (hidden_layer_sizes, activation, alpha, learning_rate) :\", mlp_model.best_params_)\n",
    "# Evaluation du mod√®le Perceptron\n",
    "evaluate_model(mlp_model.best_estimator_, X_val, y_val)\n",
    "Passons maintenant √† un mod√®le SVM\n",
    "### 3.4 Entra√Ænement et √âvaluation du Support Vector Machine (SVM)\n",
    "# SVM : Classifieur qui trouve l'hyperplan optimal qui maximise la fronti√®re entre 2 classes\n",
    "svm = SVC(random_state=seed, probability=True)\n",
    "\n",
    "# Dictionnaire des hyperparam√®tres pour SVM\n",
    "param_grid_svm = {'C': [0.01, 0.1, 1, 10, 50, 100],\n",
    "                  'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                   # 'gamma': ['scale', 'auto'],\n",
    "                   # 'degree': [2, 3, 4, 5]\n",
    "                   }\n",
    "# Objet GridSearchCV\n",
    "grid_svm_class = GridSearchCV(estimator=svm, param_grid=param_grid_svm, \n",
    "                             scoring='f1', cv=5, n_jobs=-1)\n",
    "# Entrainement du mod√®le SVM\n",
    "svm_model = grid_svm_class.fit(train_features, train_labels)\n",
    "# Meilleur score et meilleur hyperparam√®tre\n",
    "print(\"Meilleur score (f1) :\", round(svm_model.best_score_, 3))\n",
    "print(\"Meilleur hyperparam√®tre (C, kernel) :\", svm_model.best_params_)\n",
    "# meilleur mod√®le\n",
    "print(\"Meilleur mod√®le :\", svm_model.best_estimator_)\n",
    "# Evaluation du mod√®le SVM\n",
    "evaluate_model(svm_model.best_estimator_, X_val, y_val)\n",
    "\n",
    "\n",
    "## 4. S√©lection du Meilleur Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8384cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
